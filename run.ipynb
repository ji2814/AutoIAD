{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a68de750",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import time\n",
                "\n",
                "from core.prompts import (\n",
                "    create_manager_prompt,\n",
                "    create_data_loader_prompt,\n",
                "    create_data_processor_prompt,\n",
                "    create_model_designer_prompt,\n",
                "    create_trainer_prompt,\n",
                ")\n",
                "from core.tools import (\n",
                "    list_files,\n",
                "    read_files,\n",
                "    preview_file_content,\n",
                "    tree,\n",
                "    write_to_file,\n",
                "    copy_file,\n",
                "    run_script,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "078d4126",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_openai import ChatOpenAI\n",
                "from langchain_community.callbacks.openai_info import OpenAICallbackHandler\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "callback_manager = OpenAICallbackHandler()\n",
                "\n",
                "model_name = \"google/gemini-2.5-flash\" \n",
                "prompt_cost_per_million = 0.15\n",
                "completion_cost_per_million = 0.60\n",
                "class_name = \"bottle\"\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "04af4a4f",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "load_dotenv()\n",
                "api_key = \"sk-xxx\" # or os.environ[\"OPENAI_API_KEY\"]\n",
                "base_url = \"base_url\" # or os.environ[\"OPENAI_API_BASE\"]\n",
                "\n",
                "llm = ChatOpenAI(\n",
                "    openai_api_key=api_key,\n",
                "    model_name=model_name,\n",
                "    base_url=base_url,\n",
                "    callbacks=[callback_manager],\n",
                "    extra_body={\"enable_thinking\": False},\n",
                ")\n",
                "\n",
                "\n",
                "task_card = json.load(open(os.path.join(\"TaskCard.json\"), \"r\"))\n",
                "\n",
                "work_path = \"workspace\"\n",
                "knowledge_path = \"knowledge\" \n",
                "\n",
                "recursion_limit = 100\n",
                "\n",
                "DRAW_AGRNT = False\n",
                "RUN_AGENT = False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "73ef68b5",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Task card test:\", task_card)  # test task card\n",
                "print(\"LLM test:\", llm.invoke(\"hello! Who are you?\",  extra_body={\"enable_thinking\": False},))  # test llm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f238fc0f",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langgraph.prebuilt import create_react_agent\n",
                "from core.utils import pretty_print_messages\n",
                "\n",
                "\n",
                "def build_worker(name, llm, tools, prompt):\n",
                "    agent = create_react_agent(model=llm, tools=tools, prompt=prompt, name=name)\n",
                "    return agent\n",
                "from core.utils import timeout\n",
                "\n",
                "@timeout(600)\n",
                "def run_agent(agent, prompt, recursion_limit=100):\n",
                "    for chunk in agent.stream(\n",
                "        {\"messages\": [{\"role\": \"user\", \"content\": prompt}]},\n",
                "        {\"recursion_limit\": recursion_limit},\n",
                "    ):\n",
                "        pretty_print_messages(chunk)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "adc3004c",
            "metadata": {},
            "outputs": [],
            "source": [
                "from IPython.display import Image, display\n",
                "from langchain_core.runnables.graph import MermaidDrawMethod\n",
                "\n",
                "\n",
                "def draw_graph(agent):\n",
                "    display(\n",
                "        Image(\n",
                "            agent.get_graph().draw_mermaid_png(\n",
                "                draw_method=MermaidDrawMethod.API,\n",
                "            )\n",
                "        )\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "527e92e9",
            "metadata": {},
            "outputs": [],
            "source": [
                "data_processor_agent = build_worker(\n",
                "    \"data_processor\",\n",
                "    llm,\n",
                "    tools=[\n",
                "        list_files,\n",
                "        read_files,\n",
                "        preview_file_content,\n",
                "        tree,\n",
                "        write_to_file,\n",
                "        copy_file,\n",
                "        run_script,\n",
                "    ],\n",
                "    prompt=create_data_processor_prompt(work_path, task_card, knowledge_path),\n",
                ")\n",
                "\n",
                "# draw_graph(data_processor_agent)\n",
                "\n",
                "if RUN_AGENT:\n",
                "    run_agent(data_processor_agent, \"now you should make a python script and run it.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "236524c0",
            "metadata": {},
            "outputs": [],
            "source": [
                "data_loader_agent = build_worker(\n",
                "    \"data_loader\",\n",
                "    llm,\n",
                "    tools=[\n",
                "        read_files,\n",
                "        preview_file_content,\n",
                "        write_to_file,\n",
                "        copy_file,\n",
                "        run_script,\n",
                "    ],\n",
                "    prompt=create_data_loader_prompt(work_path, task_card, knowledge_path),\n",
                ")\n",
                "\n",
                "if DRAW_AGRNT:\n",
                "    draw_graph(data_loader_agent)\n",
                "if RUN_AGENT:\n",
                "    run_agent(data_loader_agent, \"now you should make a python class script and test it.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e69210ca",
            "metadata": {},
            "outputs": [],
            "source": [
                "model_designer_agent = build_worker(\n",
                "    \"model_designer\",\n",
                "    llm,\n",
                "    tools=[\n",
                "        read_files,\n",
                "        preview_file_content,\n",
                "        write_to_file,\n",
                "        copy_file,\n",
                "        run_script,\n",
                "    ],\n",
                "    prompt=create_model_designer_prompt(work_path, task_card, knowledge_path),\n",
                ")\n",
                "\n",
                "if DRAW_AGRNT:\n",
                "    draw_graph(model_designer_agent)\n",
                "if RUN_AGENT:\n",
                "    run_agent(model_designer_agent, \"now you should make a python class script and test it.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "95a644fb",
            "metadata": {},
            "outputs": [],
            "source": [
                "trainer_agent = build_worker(\n",
                "    \"trainer\",\n",
                "    llm,\n",
                "    tools=[\n",
                "        read_files,\n",
                "        preview_file_content,\n",
                "        write_to_file,\n",
                "        copy_file,\n",
                "        run_script,\n",
                "    ],\n",
                "    prompt=create_trainer_prompt(work_path, task_card, knowledge_path),\n",
                ")\n",
                "\n",
                "if DRAW_AGRNT:\n",
                "    draw_graph(trainer_agent)\n",
                "if RUN_AGENT:\n",
                "    run_agent(trainer_agent, \"now you should train the model or optimize the model.\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "181d17b9",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langgraph_supervisor import create_supervisor\n",
                "\n",
                "all_worker_agents = [\n",
                "    data_processor_agent,\n",
                "    data_loader_agent,\n",
                "    model_designer_agent,\n",
                "    trainer_agent,\n",
                "]\n",
                "\n",
                "manager = create_supervisor(\n",
                "    model=llm,\n",
                "    tools=[\n",
                "        list_files,\n",
                "        read_files,\n",
                "        preview_file_content,\n",
                "        tree,\n",
                "        run_script,\n",
                "    ],\n",
                "    agents=[\n",
                "        data_processor_agent,\n",
                "        data_loader_agent,\n",
                "        model_designer_agent,\n",
                "        trainer_agent,\n",
                "    ],\n",
                "    prompt=create_manager_prompt(\n",
                "        work_path,\n",
                "        task_card,\n",
                "        agent_names=[agent.name for agent in all_worker_agents],\n",
                "    ),\n",
                "    add_handoff_back_messages=True,\n",
                "    output_mode=\"full_history\",\n",
                "    supervisor_name=\"manager\",\n",
                ").compile()\n",
                "\n",
                "# draw_graph(manager)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0a741ff2",
            "metadata": {},
            "outputs": [],
            "source": [
                "start_time = time.time()\n",
                "try:\n",
                "    run_agent(manager, \"now you should do the task.\")\n",
                "except TimeoutError as e:\n",
                "    print(f\"TimeoutError: {e}\")\n",
                "except Exception as e:\n",
                "    print(f\"Exception: {e}\")\n",
                "finally:\n",
                "    end_time = time.time()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "85bccd66",
            "metadata": {},
            "outputs": [],
            "source": [
                "from core.utils import calculate_llm_cost\n",
                "\n",
                "# === STATS ===\n",
                "print(f\"Time used: {end_time - start_time:.2f}s\")\n",
                "total_prompt_tokens = callback_manager.prompt_tokens\n",
                "total_completion_tokens = callback_manager.completion_tokens\n",
                "total_cost = calculate_llm_cost(\n",
                "    total_prompt_tokens,\n",
                "    total_completion_tokens,\n",
                "    prompt_cost_per_million=prompt_cost_per_million,\n",
                "    completion_cost_per_million=completion_cost_per_million,\n",
                ")\n",
                "print(f\"Total Tokens Used: {total_prompt_tokens + total_completion_tokens}\")\n",
                "print(f\"Prompt Tokens: {total_prompt_tokens}\")\n",
                "print(f\"Completion Tokens: {total_completion_tokens}\")\n",
                "print(f\"Total Cost (USD): ${total_cost:.6f}\")\n",
                "\n",
                "callback_manager.prompt_tokens = 0\n",
                "callback_manager.completion_tokens = 0"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "autoIAD",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.18"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
